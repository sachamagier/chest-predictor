{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b17700cc-53b0-4ce6-b6a7-8ecc22d9f289",
   "metadata": {},
   "source": [
    "# Chest-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09965761",
   "metadata": {},
   "source": [
    "## PRELIMINARY ACTION !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef354ac",
   "metadata": {},
   "source": [
    "⚠️ Please go to ➤ https://drive.google.com/file/d/1lLrHbpUQE-Kd-jZ68Uk7SFwawbzqf6Av/view?usp=drive_link\n",
    "\n",
    "and download the dataset.\n",
    "\n",
    "Put the zip file into your \"*raw_data*\" folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faad179-7472-4314-8936-5ad2b1749114",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a9eed3c-4b31-42ba-b768-5247fe54bd26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:24:52.305002Z",
     "start_time": "2024-06-04T15:24:52.136909Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25192021",
   "metadata": {},
   "source": [
    "### Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11013ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:24:53.047521Z",
     "start_time": "2024-06-04T15:24:53.043828Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"chest-predictor\" #to be adapted depending on the name of the Project Name in your system\n",
    "NUMBER_OF_IMAGES = 3000 # nbr of images to be loaded or 'full' to load the entire dataset (+100k images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10b88e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:24:53.422560Z",
     "start_time": "2024-06-04T15:24:53.417298Z"
    }
   },
   "outputs": [],
   "source": [
    "USERNAME = os.environ.get('USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff1e5898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:24:53.721558Z",
     "start_time": "2024-06-04T15:24:53.717654Z"
    }
   },
   "outputs": [],
   "source": [
    "# I changed this so that it works on both windows and mac, but if it doesn't work uncomment the other one\n",
    "\n",
    "\n",
    "# #LOCAL_DATA_PATH = Path(f\"/Users/{USERNAME}/code/sachamagier/{PROJECT_NAME}/raw_data/resized_dataset\")\n",
    "LOCAL_DATA_PATH = Path(os.path.expanduser(f\"~/code/sachamagier/{PROJECT_NAME}/raw_data/resized_dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75f7d90a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:24:54.035890Z",
     "start_time": "2024-06-04T15:24:54.030486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL_DATA_PATH: /home/rvnmll/code/sachamagier/chest-predictor/raw_data/resized_dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"LOCAL_DATA_PATH: {LOCAL_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63c8f689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:24:54.615627Z",
     "start_time": "2024-06-04T15:24:54.605183Z"
    }
   },
   "outputs": [],
   "source": [
    "def loading_data():\n",
    "    \"\"\"This function either get all the images if the user set NUMBER_OF_IMAGES\n",
    "    to 'full' or the number of imgaes otherwise \"\"\"\n",
    "\n",
    "    images_data = []\n",
    "\n",
    "    # Define the path to the folder\n",
    "    folder_path = f'../raw_data/resized_dataset/images/set_full/'\n",
    "\n",
    "\n",
    "    # Get a list of all files in the folder\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    # Filter the list to only include image files\n",
    "    image_files = [f for f in file_list if f.endswith('.png') or f.endswith('.jpg') or f.endswith('.jpeg')]\n",
    "\n",
    "\n",
    "    # Loop through the first NUMBER_OF_IMAGES\n",
    "    for i, image_file in enumerate(image_files):\n",
    "\n",
    "        # Stop the loop after NUMBER_OF_IMAGES iterations\n",
    "        if i == NUMBER_OF_IMAGES:\n",
    "            break\n",
    "\n",
    "        # Open the image file\n",
    "        with Image.open(folder_path + image_file) as image:\n",
    "            # Add the image to the list\n",
    "            images_data.append((image_file, np.array(image)))\n",
    "\n",
    "    return images_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b06e06b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:24:56.678898Z",
     "start_time": "2024-06-04T15:24:55.216909Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load local data...\n",
      "data loaded.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "\n",
    "if LOCAL_DATA_PATH.is_dir():\n",
    "    print(\"Load local data...\")\n",
    "    # loading data into data\n",
    "    images_data = loading_data()\n",
    "else:\n",
    "    print(\"Unziping file and loading the data...\")\n",
    "\n",
    "    output_path = \"../raw_data/resized_dataset.zip\"\n",
    "    # unzip the file\n",
    "    with zipfile.ZipFile(output_path, \"r\") as zip_ref:\n",
    "        for file_info in zip_ref.infolist():\n",
    "            zip_ref.extract(file_info, \"../raw_data/\")\n",
    "\n",
    "    if Path(\"../raw_data/__MACOSX\").is_dir():\n",
    "        # remove the __MACOSX folder if it exists\n",
    "        shutil.rmtree(\"../raw_data/__MACOSX\")\n",
    "\n",
    "    # remove the zip file\n",
    "    os.remove(output_path)\n",
    "    images_data = loading_data()\n",
    "\n",
    "print(\"data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5878ae3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:24:57.867364Z",
     "start_time": "2024-06-04T15:24:57.864628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from the list of images and their indices\n",
    "images_df = pd.DataFrame(images_data, columns=['Image Index', 'image'])\n",
    "\n",
    "# Set the index of the dataframe to the 'Image Index' column\n",
    "images_df = images_df.set_index('Image Index').sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c3260861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:01.706885Z",
     "start_time": "2024-06-04T15:25:01.703082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d95bc3bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:05.553451Z",
     "start_time": "2024-06-04T15:25:05.550949Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46682/4042123707.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  images_df['image'][0].shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df['image'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c19dfa7",
   "metadata": {},
   "source": [
    "### Loading labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd26302c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:09.444332Z",
     "start_time": "2024-06-04T15:25:09.377921Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('../raw_data/resized_dataset/Data_Entry_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebeb04e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:13.294258Z",
     "start_time": "2024-06-04T15:25:13.289694Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
       "0                        0.143  0.143          NaN  \n",
       "1                        0.143  0.143          NaN  \n",
       "2                        0.168  0.168          NaN  \n",
       "3                        0.171  0.171          NaN  \n",
       "4                        0.143  0.143          NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7616c82c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:17.161156Z",
     "start_time": "2024-06-04T15:25:17.156458Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_lab = labels_df['Finding Labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "093a758b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:20.979618Z",
     "start_time": "2024-06-04T15:25:20.977761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b4c0e1",
   "metadata": {},
   "source": [
    "### Merging Images with labels and creating a new DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d12b0aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:24.846244Z",
     "start_time": "2024-06-04T15:25:24.834632Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the image_df and labels_df dataframes on the 'Image Index' column\n",
    "merged_df = pd.merge(images_df, labels_df[['Image Index', 'Finding Labels']], left_index=True, right_on='Image Index', how='inner')\n",
    "\n",
    "# Rename the 'Finding Labels' column to 'labels'\n",
    "merged_df = merged_df.rename(columns={'Finding Labels': 'labels'})\n",
    "\n",
    "# Set the index of the dataframe to the 'Image Index' column\n",
    "merged_df = merged_df.set_index('Image Index').sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33ae856d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:31.552859Z",
     "start_time": "2024-06-04T15:25:31.401078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000005_003.png</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>No Finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000006_000.png</th>\n",
       "      <td>[[45, 43, 38, 34, 30, 27, 24, 21, 19, 17, 16, ...</td>\n",
       "      <td>No Finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000013_031.png</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>Emphysema|Mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000017_002.png</th>\n",
       "      <td>[[14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, ...</td>\n",
       "      <td>No Finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000018_000.png</th>\n",
       "      <td>[[32, 30, 26, 24, 24, 23, 23, 22, 22, 22, 21, ...</td>\n",
       "      <td>No Finding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              image  \\\n",
       "Image Index                                                           \n",
       "00000005_003.png  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "00000006_000.png  [[45, 43, 38, 34, 30, 27, 24, 21, 19, 17, 16, ...   \n",
       "00000013_031.png  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "00000017_002.png  [[14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, ...   \n",
       "00000018_000.png  [[32, 30, 26, 24, 24, 23, 23, 22, 22, 22, 21, ...   \n",
       "\n",
       "                          labels  \n",
       "Image Index                       \n",
       "00000005_003.png      No Finding  \n",
       "00000006_000.png      No Finding  \n",
       "00000013_031.png  Emphysema|Mass  \n",
       "00000017_002.png      No Finding  \n",
       "00000018_000.png      No Finding  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510e98e",
   "metadata": {},
   "source": [
    "### droping the rows with images of shape (256, 256, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9bed4d30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:38.095724Z",
     "start_time": "2024-06-04T15:25:38.093872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Find the images with shape (256, 256, 4)\n",
    "images_with_shape_4 = [img for img in merged_df['image'] if np.shape(img) == (256, 256, 4)]\n",
    "\n",
    "# Print the number of images with shape (256, 256, 4)\n",
    "print(len(images_with_shape_4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ded8a7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:48.480750Z",
     "start_time": "2024-06-04T15:25:48.474533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the indices of the images with shape (256, 256, 4)\n",
    "indices_to_drop = merged_df[merged_df['image'].apply(lambda x: np.shape(x) == (256, 256, 4))].index\n",
    "\n",
    "# Drop the rows with the images with shape (256, 256, 4)\n",
    "merged_df = merged_df.drop(indices_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9059ba4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:25:55.271167Z",
     "start_time": "2024-06-04T15:25:55.269104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Find the images with shape (256, 256, 4)\n",
    "images_with_shape_4 = [img for img in merged_df['image'] if np.shape(img) == (256, 256, 4)]\n",
    "\n",
    "# Print the number of images with shape (256, 256, 4)\n",
    "print(len(images_with_shape_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bbd3fc",
   "metadata": {},
   "source": [
    "### Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "426c34bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:26:01.867392Z",
     "start_time": "2024-06-04T15:26:01.861222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the list of labels\n",
    "labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema',\n",
    "           'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n",
    "           'Cardiomegaly', 'Nodule', 'Mass', 'Hernia', 'No Finding']\n",
    "\n",
    "# Create a new dataframe with one-hot encoded columns for the labels\n",
    "one_hot_df = merged_df['labels'].str.get_dummies(sep='|')\n",
    "\n",
    "# Concatenate the one-hot encoded dataframe with the original dataframe\n",
    "merged_df = pd.concat([merged_df, one_hot_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09dd0cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:26:15.441293Z",
     "start_time": "2024-06-04T15:26:15.439327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image', 'labels', 'Atelectasis', 'Cardiomegaly', 'Consolidation',\n",
       "       'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n",
       "       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n",
       "       'Pneumothorax'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748dc4b7",
   "metadata": {},
   "source": [
    "## Creating 'X' and 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df2d7cba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:26:22.020519Z",
     "start_time": "2024-06-04T15:26:22.019180Z"
    }
   },
   "outputs": [],
   "source": [
    "y = one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "204b7dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:26:28.573970Z",
     "start_time": "2024-06-04T15:26:28.572586Z"
    }
   },
   "outputs": [],
   "source": [
    "X = merged_df['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7fac4de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:26:55.900807Z",
     "start_time": "2024-06-04T15:26:55.897795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 2991 entries, 00000005_003.png to 00030797_000.png\n",
      "Series name: image\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "2991 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 187.5 MB\n"
     ]
    }
   ],
   "source": [
    "X.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8a6a99c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:27:05.009712Z",
     "start_time": "2024-06-04T15:27:05.000383Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array([np.reshape(img, (256, 256, 1)) for img in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c1b7442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T15:27:31.705738Z",
     "start_time": "2024-06-04T15:27:31.704027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2991, 256, 256, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a2def",
   "metadata": {},
   "source": [
    "## Creating a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09300ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "772cda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Splitting X and y in train/val/test #####\n",
    "\n",
    "# First split: split data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# Second split: split training data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee559184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image parameters\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66debdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import metrics\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, precision_score, recall_score\n",
    "\n",
    "# Some extra metrics that we'll use to evaluate our model\n",
    "def EMR(y_pred, y_test):\n",
    "    \"\"\" Exact Match ratio, this takes the ratio of exact matches per samble.\n",
    "    A prediction of a sample that accurately predicts ALL lables will be considered\n",
    "    an Exact match, we cound all the exact matches and divide them by the sample\n",
    "    amount to get the EM ratio\n",
    "    \"\"\"\n",
    "    return np.all(y_pred == y_test, axis=1).mean()\n",
    "\n",
    "def hamming_score_value(y_pred, y_test):\n",
    "    \"\"\"Proportion of the predicted correct labels to the total number (predicted and actual) of labels\n",
    "    for that instance. Overall accuracy is the average across all instances.\n",
    "    We use the hamming loss because it's the opposite of the hamming score, it reports\n",
    "    how many times on average, the relevance of an example to a class label is incorrectly predicted.\n",
    "    \"\"\"\n",
    "    return 1 - hamming_loss(y_pred, y_test)\n",
    "\n",
    "def average_precision(y_pred, y_test):\n",
    "    return precision_score(y_test, y_pred, average='samples', zero_division=0)\n",
    "def average_recall(y_pred, y_test):\n",
    "    return recall_score(y_test, y_pred, average='samples')\n",
    "\n",
    "def evaluating_model(y_pred, y_test):\n",
    "    print('Exact Match Ratio:', EMR(y_pred, y_test)),\n",
    "    print('Hamming Score:', hamming_score_value(y_pred, y_test)),\n",
    "    print('Average Precision:', average_precision(y_pred, y_test)),\n",
    "    print('Average Recall:', average_recall(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "465d9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple model\n",
    "def simple_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Rescaling(1./255, input_shape=(IMG_HEIGHT,IMG_WIDTH,1)))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=10, activation='relu'))\n",
    "    model.add(MaxPooling2D(3))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(3))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "515e1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '../models' #This is where the best models will be saved\n",
    "\n",
    "# Ensure that the directory exists\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   patience=10,\n",
    "                   verbose=0,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath= os.path.join(models_dir, 'simple_model_best.h5'),\n",
    "                                   save_best_only=True,\n",
    "                                   monitor='val_loss',\n",
    "                                   mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6658a095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_8 (Rescaling)     (None, 256, 256, 1)       0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 247, 247, 16)      1616      \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPooli  (None, 82, 82, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 75, 75, 32)        32800     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 25, 25, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 20, 20, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPooli  (None, 6, 6, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               115300    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 15)                1515      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188127 (734.87 KB)\n",
      "Trainable params: 188127 (734.87 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "s_model = simple_model()\n",
    "s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80f4823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 14s 203ms/step - loss: 0.2623 - accuracy: 0.5180 - val_loss: 0.2230 - val_accuracy: 0.5511\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rvnmll/.pyenv/versions/3.10.6/envs/chest-predictor/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 13s 216ms/step - loss: 0.2239 - accuracy: 0.5311 - val_loss: 0.2209 - val_accuracy: 0.5511\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 12s 207ms/step - loss: 0.2242 - accuracy: 0.5306 - val_loss: 0.2203 - val_accuracy: 0.5511\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 13s 214ms/step - loss: 0.2218 - accuracy: 0.5248 - val_loss: 0.2212 - val_accuracy: 0.5511\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 15s 242ms/step - loss: 0.2197 - accuracy: 0.5306 - val_loss: 0.2210 - val_accuracy: 0.5511\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 15s 251ms/step - loss: 0.2165 - accuracy: 0.5243 - val_loss: 0.2193 - val_accuracy: 0.5511\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 15s 258ms/step - loss: 0.2163 - accuracy: 0.5233 - val_loss: 0.2195 - val_accuracy: 0.5073\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 16s 269ms/step - loss: 0.2151 - accuracy: 0.5227 - val_loss: 0.2171 - val_accuracy: 0.5386\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 20s 328ms/step - loss: 0.2154 - accuracy: 0.5186 - val_loss: 0.2222 - val_accuracy: 0.5324\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 17s 286ms/step - loss: 0.2146 - accuracy: 0.5264 - val_loss: 0.2193 - val_accuracy: 0.5470\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = s_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[es, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "df39cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 66ms/step - loss: 0.2217 - accuracy: 0.5142\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.2193 - accuracy: 0.5470\n",
      "val accuracy: 0.5469728708267212\n",
      "test accuracy: 0.5141903162002563\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = s_model.evaluate(X_test, y_test)\n",
    "val_loss, val_accuracy = s_model.evaluate(X_val, y_val)\n",
    "print('val accuracy:', val_accuracy)\n",
    "print('test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c16c0365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 66ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = s_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3546c1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1611082 , 0.08431179, 0.04302759, 0.0482697 , 0.23415886,\n",
       "       0.0681626 , 0.03675291, 0.01000772, 0.30514473, 0.14327462,\n",
       "       0.501417  , 0.10649241, 0.03310282, 0.00968514, 0.08492978],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "012309e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000005_003.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000006_000.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000013_031.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000017_002.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000018_000.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Atelectasis  Cardiomegaly  Consolidation  Edema  Effusion  \\\n",
       "Image Index                                                                   \n",
       "00000005_003.png            0             0              0      0         0   \n",
       "00000006_000.png            0             0              0      0         0   \n",
       "00000013_031.png            0             0              0      0         0   \n",
       "00000017_002.png            0             0              0      0         0   \n",
       "00000018_000.png            0             0              0      0         0   \n",
       "\n",
       "                  Emphysema  Fibrosis  Hernia  Infiltration  Mass  No Finding  \\\n",
       "Image Index                                                                     \n",
       "00000005_003.png          0         0       0             0     0           1   \n",
       "00000006_000.png          0         0       0             0     0           1   \n",
       "00000013_031.png          1         0       0             0     1           0   \n",
       "00000017_002.png          0         0       0             0     0           1   \n",
       "00000018_000.png          0         0       0             0     0           1   \n",
       "\n",
       "                  Nodule  Pleural_Thickening  Pneumonia  Pneumothorax  \n",
       "Image Index                                                            \n",
       "00000005_003.png       0                   0          0             0  \n",
       "00000006_000.png       0                   0          0             0  \n",
       "00000013_031.png       0                   0          0             0  \n",
       "00000017_002.png       0                   0          0             0  \n",
       "00000018_000.png       0                   0          0             0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "745f9f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Ratio: 0.44574290484140233\n",
      "Hamming Score: 0.9225375626043406\n",
      "Average Precision: 0.44741235392320533\n",
      "Average Recall: 0.44629938786866996\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rvnmll/.pyenv/versions/3.10.6/envs/chest-predictor/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Because we need binary results to evaluate the model we'll put a threshold\n",
    "#that will transform the values to either 0 or 1\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "print(evaluating_model(y_pred_binary, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85cda6",
   "metadata": {},
   "source": [
    "## We train a more complex model to see how our scores change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0484a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a more complex model\n",
    "model = Sequential()\n",
    "model.add(Rescaling(1./255, input_shape=(IMG_HEIGHT,IMG_WIDTH,1)))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1d0fa7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint = ModelCheckpoint(filepath= os.path.join(models_dir, 'better_model.h5'),\n",
    "#                                    save_best_only=True,\n",
    "#                                    monitor='val_loss',\n",
    "#                                    mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ff7dc160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_15 (Rescaling)    (None, 256, 256, 1)       0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 254, 254, 16)      160       \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 254, 254, 16)      64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPooli  (None, 127, 127, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 127, 127, 16)      0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 125, 125, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPooli  (None, 62, 62, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 62, 62, 32)        0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 60, 60, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPooli  (None, 30, 30, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 28, 28, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPooli  (None, 14, 14, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               3211392   \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 25)                3225      \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 25)                100       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 25)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 15)                390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3313731 (12.64 MB)\n",
      "Trainable params: 3312945 (12.64 MB)\n",
      "Non-trainable params: 786 (3.07 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f77a6ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60/60 [==============================] - 31s 449ms/step - loss: 0.7748 - accuracy: 0.0831 - val_loss: 1.0221 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 25s 424ms/step - loss: 0.6705 - accuracy: 0.1505 - val_loss: 1.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 26s 432ms/step - loss: 0.5838 - accuracy: 0.2295 - val_loss: 1.7529 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 27s 459ms/step - loss: 0.4701 - accuracy: 0.3612 - val_loss: 0.3694 - val_accuracy: 0.1587\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 29s 486ms/step - loss: 0.3756 - accuracy: 0.4344 - val_loss: 2.4866 - val_accuracy: 0.0313\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 28s 460ms/step - loss: 0.2999 - accuracy: 0.4663 - val_loss: 0.3204 - val_accuracy: 0.1273\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 26s 440ms/step - loss: 0.2615 - accuracy: 0.5039 - val_loss: 0.3192 - val_accuracy: 0.1378\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 26s 433ms/step - loss: 0.2415 - accuracy: 0.5128 - val_loss: 0.2780 - val_accuracy: 0.4635\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 30s 495ms/step - loss: 0.2331 - accuracy: 0.5186 - val_loss: 0.2500 - val_accuracy: 0.4322\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 30s 496ms/step - loss: 0.2271 - accuracy: 0.5212 - val_loss: 0.2577 - val_accuracy: 0.4906\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 30s 491ms/step - loss: 0.2216 - accuracy: 0.5159 - val_loss: 0.2462 - val_accuracy: 0.5115\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 27s 457ms/step - loss: 0.2205 - accuracy: 0.5227 - val_loss: 0.2402 - val_accuracy: 0.5532\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 24s 394ms/step - loss: 0.2192 - accuracy: 0.5206 - val_loss: 0.2201 - val_accuracy: 0.5511\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 24s 407ms/step - loss: 0.2183 - accuracy: 0.5248 - val_loss: 0.2238 - val_accuracy: 0.5470\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 24s 402ms/step - loss: 0.2165 - accuracy: 0.5133 - val_loss: 0.2436 - val_accuracy: 0.5491\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 23s 390ms/step - loss: 0.2152 - accuracy: 0.5259 - val_loss: 0.2398 - val_accuracy: 0.5511\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 25s 413ms/step - loss: 0.2126 - accuracy: 0.5159 - val_loss: 0.2258 - val_accuracy: 0.5511\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 24s 397ms/step - loss: 0.2104 - accuracy: 0.5248 - val_loss: 0.2198 - val_accuracy: 0.5428\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 25s 417ms/step - loss: 0.2099 - accuracy: 0.5238 - val_loss: 0.2279 - val_accuracy: 0.5428\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 24s 403ms/step - loss: 0.2082 - accuracy: 0.5201 - val_loss: 0.2534 - val_accuracy: 0.5449\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 24s 403ms/step - loss: 0.2096 - accuracy: 0.5327 - val_loss: 0.2507 - val_accuracy: 0.5532\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 26s 437ms/step - loss: 0.2051 - accuracy: 0.5348 - val_loss: 0.2244 - val_accuracy: 0.5532\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 24s 408ms/step - loss: 0.2090 - accuracy: 0.5274 - val_loss: 0.2189 - val_accuracy: 0.5470\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 24s 405ms/step - loss: 0.2065 - accuracy: 0.5285 - val_loss: 0.2194 - val_accuracy: 0.5470\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 27s 443ms/step - loss: 0.2059 - accuracy: 0.5233 - val_loss: 0.2275 - val_accuracy: 0.5491\n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 25s 419ms/step - loss: 0.2069 - accuracy: 0.5269 - val_loss: 0.2224 - val_accuracy: 0.5449\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 26s 429ms/step - loss: 0.2051 - accuracy: 0.5337 - val_loss: 0.2146 - val_accuracy: 0.5491\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 27s 444ms/step - loss: 0.2015 - accuracy: 0.5353 - val_loss: 0.2152 - val_accuracy: 0.5344\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 26s 428ms/step - loss: 0.2058 - accuracy: 0.5301 - val_loss: 0.2161 - val_accuracy: 0.5407\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 27s 449ms/step - loss: 0.1998 - accuracy: 0.5306 - val_loss: 0.2153 - val_accuracy: 0.5365\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c0a03fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 113ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bba6b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Ratio: 0.2938230383973289\n",
      "Hamming Score: 0.9228714524207011\n",
      "Average Precision: 0.2938230383973289\n",
      "Average Recall: 0.2938230383973289\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "print(evaluating_model(y_pred_binary, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2794074",
   "metadata": {},
   "source": [
    "## I try also vgg16 architecture to see if the performance increases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e203a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed4df32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vg16_based__model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Rescaling(1./255, input_shape=(IMG_HEIGHT,IMG_WIDTH,1)))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(Conv2D(64, kernel_size=3, padding = 'same', activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(Conv2D(128, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(Conv2D(256, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(Conv2D(256, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(Conv2D(512, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(Conv2D(512, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(Conv2D(512, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(Conv2D(512, kernel_size=3, padding = 'same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='relu', name = 'fc1'))\n",
    "    model.add(Dense(128, activation='relu', name = 'fc2'))\n",
    "    model.add(Dense(25, activation='relu', name = 'fc3'))\n",
    "    model.add(Dense(NUM_CLASSES, activation='sigmoid', name = 'ouput'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd48d862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 256, 256, 1)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 256, 256, 64)      640       \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 128, 128, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 64, 64, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 32, 32, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 16, 16, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 8, 8, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 256)               8388864   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               32896     \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 25)                3225      \n",
      "                                                                 \n",
      " ouput (Dense)               (None, 15)                390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23138911 (88.27 MB)\n",
      "Trainable params: 23138911 (88.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vg16_based__model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde90f1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      2\u001b[0m     X_train,\n\u001b[1;32m      3\u001b[0m     y_train,\n\u001b[1;32m      4\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[1;32m      5\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      7\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[es])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081e1c6",
   "metadata": {},
   "source": [
    "## We can also try to create a transfer model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6a2f0572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def load_model():\n",
    "\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape=X_train[0].shape)\n",
    "\n",
    "    # $CHALLENGIFY_END\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cabcfa10",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; Received `input_shape=(256, 256, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transfer_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m transfer_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[169], line 7\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m():\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# $CHALLENGIFY_BEGIN\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# $CHALLENGIFY_END\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chest-predictor/lib/python3.10/site-packages/keras/src/applications/vgg16.py:137\u001b[0m, in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf using `weights` as `\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` with `include_top` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas true, `classes` should be 1000.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `classes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Determine proper input shape\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mimagenet_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_input_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_flatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     img_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chest-predictor/lib/python3.10/site-packages/keras/src/applications/imagenet_utils.py:402\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`input_shape` must be a tuple of three integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    400\u001b[0m     )\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input must have 3 channels; Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`input_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m     )\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    407\u001b[0m     input_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m min_size\n\u001b[1;32m    408\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (input_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m min_size):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput size must be at least \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; Received `input_shape=(256, 256, 1)`"
     ]
    }
   ],
   "source": [
    "transfer_model = load_model()\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd14f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
